% Present the answer to RQ1

\input{tables/occurrence_table}

{\bf Answering RQ1}. Table~\ref{tab:annotation_table} furnishes the evaluation
metrics arising from the manual annotation study of \texttt{TreeNose} and the
other language-specific tools.
%
In this table, TN represents \texttt{TreeNose}, and LS represents a
language-specific tool.
%
When there is no value in this table, it means that it is not possible to
calculate the recall, per the methodology described in
Section~\ref{sec:evaluation}.
%
For example, when \texttt{TreeNose} was the baseline technique, it suggested
all of the code smells from which we randomly sampled and thus it is not
possible to calculate the recall or the F1 score of \texttt{TreeNose} in this
environment, with the same applying to the LS-selected samples.
%
Overall, Table~\ref{tab:annotation_table} shows that \texttt{TreeNose}
significantly outperformed the other tools in terms of precision, recall, and
F1 score.
%
For instance, it exhibits an F1 score of 0.94 compared to one of 0.48 for the
language-specific detectors.
%
Interestingly, the language-specific detectors achieve a precision of 1.0 for
the \texttt{TreeNose}-selected samples, but their recall is down to 0.32,
resulting in the aforementioned low F1 score of 0.48.

% This indicates that the LS group can hardly detect all the code smells in the
% \texttt{TreeNose}--selected samples.

{\bf Answering RQ2}. Table~\ref{tab:percentage_table} furnishes the percentage
of the code smells in each programming language. This table shows that the
Complex Conditional (CC) code smell accounts for 46\% of code smells on
average, indicating that it is the most common code smell across programming
languages.
%
The table also reveals that the percentage of Long Class (LC) and Long Method
(LM) vary significantly in the Java and JavaScript projects. In the Java
projects, LC occurs 7 times more than LM, while in the JavaScript projects it
is the opposite as LM occurs 30 times more than LC. This suggests that
programming languages have different code smell tendencies.

{\bf Answering RQ3}. Table~\ref{tab:occurrence_table} shows the occurrence
discrepancy scores of the code smells across the chosen languages. Since no
programming language contains positive values in every code smell, we conclude
that no programming language ``outperforms'' the others for every code smell.
By looking at each code smell, this table shows that programming languages have
strong tendencies for certain code smells.
%
For example, the Java projects have a strong tendency to exhibit Long Class
(LC), with 1.24 times worse performance and Long Message Chain (LMC) with 3.56
worse performance than others, while the JavaScript projects have a strong
tendency for the Long Method (LM) code smell. Python has a strong tendency to
exhibit Long Parameter List (LPL) smells. However, multi-language projects have
less pronounced code smell tendencies compared to the single-language projects,
with values for the discrepancy metric $D$ ranging between -0.23 and 0.70.
